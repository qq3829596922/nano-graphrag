#!/usr/bin/env python3
"""
ğŸ“š Module 1: å­˜å‚¨ç³»ç»Ÿå­¦ä¹ 
å­¦ä¹ GraphRAGå¦‚ä½•ç»„ç»‡å’Œå­˜å‚¨æ•°æ®

å­¦ä¹ ç›®æ ‡ï¼š
1. ç†è§£ä¸åŒç±»å‹çš„å­˜å‚¨ï¼ˆKVå­˜å‚¨ã€å‘é‡æ•°æ®åº“ã€å›¾å­˜å‚¨ï¼‰
2. è§‚å¯Ÿæ•°æ®çš„å®é™…å­˜å‚¨æ ¼å¼
3. ç†è§£å‘½åç©ºé—´çš„æ¦‚å¿µ
4. å­¦ä¼šæ‰‹åŠ¨æ“ä½œå­˜å‚¨ç³»ç»Ÿ

å‰ç½®æ¡ä»¶ï¼šæ— 
é¢„è®¡æ—¶é—´ï¼š30åˆ†é’Ÿ
"""

import asyncio
import json
from pathlib import Path
from nano_graphrag._storage import JsonKVStorage, NanoVectorDBStorage, NetworkXStorage

class StorageExplorer:
    """å­˜å‚¨ç³»ç»Ÿæ¢ç´¢å™¨"""
    
    def __init__(self):
        self.working_dir = "./storage_demo"
        Path(self.working_dir).mkdir(exist_ok=True)
        
    async def demo_kv_storage(self):
        """æ¼”ç¤ºé”®å€¼å­˜å‚¨"""
        print("ğŸ”‘ æ¼”ç¤º 1ï¼šé”®å€¼å­˜å‚¨ (JsonKVStorage)")
        print("=" * 40)
        
        # åˆ›å»ºå­˜å‚¨å®ä¾‹
        storage = JsonKVStorage(
            namespace="demo_docs",
            global_config={"working_dir": self.working_dir}
        )
        
        print("ğŸ“ æ’å…¥ä¸€äº›ç¤ºä¾‹æ•°æ®...")
        test_data = {
            "doc1": {"content": "è¿™æ˜¯ç¬¬ä¸€ç¯‡æ–‡æ¡£", "author": "å¼ ä¸‰"},
            "doc2": {"content": "è¿™æ˜¯ç¬¬äºŒç¯‡æ–‡æ¡£", "author": "æå››"},
            "doc3": {"content": "è¿™æ˜¯ç¬¬ä¸‰ç¯‡æ–‡æ¡£", "author": "ç‹äº”"}
        }
        
        await storage.upsert(test_data)
        print(f"âœ… å·²æ’å…¥ {len(test_data)} æ¡è®°å½•")
        
        print("\nğŸ” æ£€ç´¢æ•°æ®...")
        # è·å–å•ä¸ªè®°å½•
        doc1 = await storage.get_by_id("doc1")
        print(f"è·å– doc1: {doc1}")
        
        # è·å–å¤šä¸ªè®°å½•
        docs = await storage.get_by_ids(["doc1", "doc2"])
        print(f"è·å–å¤šä¸ªæ–‡æ¡£: {len(docs)} æ¡")
        
        print("\nğŸ“ æ£€æŸ¥å­˜å‚¨æ–‡ä»¶...")
        storage_file = Path(self.working_dir) / "demo_docs.json"
        if storage_file.exists():
            print(f"å­˜å‚¨æ–‡ä»¶ä½ç½®: {storage_file}")
            with open(storage_file, 'r', encoding='utf-8') as f:
                content = json.load(f)
            print(f"æ–‡ä»¶å†…å®¹é¢„è§ˆ: {list(content.keys())}")
        
        print("\nğŸ¤” æ€è€ƒé¢˜ï¼š")
        print("1. KVå­˜å‚¨é€‚åˆå­˜å‚¨ä»€ä¹ˆç±»å‹çš„æ•°æ®ï¼Ÿ")
        print("2. ä¸ºä»€ä¹ˆä½¿ç”¨JSONæ ¼å¼å­˜å‚¨ï¼Ÿ")
        print("3. namespaceå‚æ•°çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ")
        input("æŒ‰å›è½¦ç»§ç»­...")
        
    async def demo_vector_storage(self):
        """æ¼”ç¤ºå‘é‡å­˜å‚¨"""
        print("\nğŸ¯ æ¼”ç¤º 2ï¼šå‘é‡å­˜å‚¨ (NanoVectorDBStorage)")
        print("=" * 40)
        
        # ç®€å•çš„åµŒå…¥å‡½æ•°ï¼ˆå®é™…ä¸­ä¼šä½¿ç”¨OpenAIç­‰APIï¼‰
        async def simple_embedding(texts):
            """ç®€å•çš„åµŒå…¥å‡½æ•°ç¤ºä¾‹"""
            import random
            return [[random.random() for _ in range(4)] for _ in texts]
        
        # åˆ›å»ºå‘é‡å­˜å‚¨
        vector_storage = NanoVectorDBStorage(
            namespace="demo_vectors",
            global_config={"working_dir": self.working_dir},
            embedding_func=simple_embedding
        )
        
        print("ğŸ“ æ’å…¥å‘é‡æ•°æ®...")
        vector_data = {
            "text1": {"content": "äººå·¥æ™ºèƒ½æ˜¯æœªæ¥"},
            "text2": {"content": "æœºå™¨å­¦ä¹ å¾ˆæœ‰è¶£"},  
            "text3": {"content": "æ·±åº¦å­¦ä¹ æ•ˆæœå¥½"}
        }
        
        await vector_storage.upsert(vector_data)
        print(f"âœ… å·²æ’å…¥ {len(vector_data)} ä¸ªå‘é‡")
        
        print("\nğŸ” ç›¸ä¼¼æ€§æœç´¢...")
        # æœç´¢ç›¸ä¼¼å†…å®¹
        results = await vector_storage.query("äººå·¥æ™ºèƒ½", top_k=2)
        print("æœç´¢ç»“æœ:")
        for i, result in enumerate(results):
            print(f"  {i+1}. ID: {result['id']}, ç›¸ä¼¼åº¦: {result.get('distance', 'N/A')}")
        
        print("\nğŸ“ æ£€æŸ¥å‘é‡å­˜å‚¨æ–‡ä»¶...")
        vector_dir = Path(self.working_dir) / "demo_vectors"
        if vector_dir.exists():
            print(f"å‘é‡å­˜å‚¨ç›®å½•: {vector_dir}")
            print("ç›®å½•å†…å®¹:")
            for file in vector_dir.iterdir():
                print(f"  ğŸ“„ {file.name}")
        
        print("\nğŸ¤” æ€è€ƒé¢˜ï¼š")
        print("1. å‘é‡å­˜å‚¨å’ŒKVå­˜å‚¨æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ")
        print("2. ä¸ºä»€ä¹ˆéœ€è¦åµŒå…¥å‡½æ•°ï¼Ÿ")
        print("3. ç›¸ä¼¼æ€§æœç´¢æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ")
        input("æŒ‰å›è½¦ç»§ç»­...")
        
    async def demo_graph_storage(self):
        """æ¼”ç¤ºå›¾å­˜å‚¨"""
        print("\nğŸ•¸ï¸ æ¼”ç¤º 3ï¼šå›¾å­˜å‚¨ (NetworkXStorage)")
        print("=" * 40)
        
        # åˆ›å»ºå›¾å­˜å‚¨
        graph_storage = NetworkXStorage(
            namespace="demo_graph",
            global_config={"working_dir": self.working_dir}
        )
        
        print("ğŸ“ æ·»åŠ å®ä½“å’Œå…³ç³»...")
        
        # æ·»åŠ å®ä½“
        entities = [
            {"entity_name": "è‹¹æœå…¬å¸", "entity_type": "ç»„ç»‡"},
            {"entity_name": "iPhone", "entity_type": "äº§å“"},
            {"entity_name": "ä¹”å¸ƒæ–¯", "entity_type": "äººç‰©"}
        ]
        
        for entity in entities:
            await graph_storage.upsert_node(
                entity["entity_name"], 
                node_data=entity
            )
        
        # æ·»åŠ å…³ç³»
        relations = [
            ("è‹¹æœå…¬å¸", "å¼€å‘", "iPhone"),
            ("ä¹”å¸ƒæ–¯", "åˆ›ç«‹", "è‹¹æœå…¬å¸"),
            ("ä¹”å¸ƒæ–¯", "å‘å¸ƒ", "iPhone")
        ]
        
        for source, relation, target in relations:
            await graph_storage.upsert_edge(
                source, target,
                edge_data={"relation": relation}
            )
        
        print(f"âœ… å·²æ·»åŠ  {len(entities)} ä¸ªå®ä½“å’Œ {len(relations)} ä¸ªå…³ç³»")
        
        print("\nğŸ” å›¾åˆ†æ...")
        # è·å–èŠ‚ç‚¹ä¿¡æ¯
        apple_node = await graph_storage.get_node("è‹¹æœå…¬å¸")
        print(f"è‹¹æœå…¬å¸èŠ‚ç‚¹: {apple_node}")
        
        # è·å–é‚»å±…
        neighbors = await graph_storage.get_node_edges("è‹¹æœå…¬å¸")
        print(f"è‹¹æœå…¬å¸çš„å…³ç³»: {len(neighbors)} ä¸ª")
        
        print("\nğŸ“ æ£€æŸ¥å›¾å­˜å‚¨æ–‡ä»¶...")
        graph_file = Path(self.working_dir) / "demo_graph.graphml"
        if graph_file.exists():
            print(f"å›¾æ–‡ä»¶ä½ç½®: {graph_file}")
            print(f"æ–‡ä»¶å¤§å°: {graph_file.stat().st_size} å­—èŠ‚")
        
        print("\nğŸ¤” æ€è€ƒé¢˜ï¼š")
        print("1. å›¾å­˜å‚¨é€‚åˆè¡¨ç¤ºä»€ä¹ˆç±»å‹çš„æ•°æ®ï¼Ÿ")
        print("2. èŠ‚ç‚¹å’Œè¾¹åˆ†åˆ«å­˜å‚¨ä»€ä¹ˆä¿¡æ¯ï¼Ÿ")
        print("3. GraphMLæ ¼å¼æ˜¯ä»€ä¹ˆï¼Ÿ")
        input("æŒ‰å›è½¦ç»§ç»­...")
        
    def explore_storage_files(self):
        """æ¢ç´¢ç”Ÿæˆçš„å­˜å‚¨æ–‡ä»¶"""
        print("\nğŸ“ å­˜å‚¨æ–‡ä»¶æ€»è§ˆ")
        print("=" * 40)
        
        working_dir = Path(self.working_dir)
        if not working_dir.exists():
            print("æ²¡æœ‰æ‰¾åˆ°å­˜å‚¨æ–‡ä»¶")
            return
            
        print("ç”Ÿæˆçš„æ–‡ä»¶å’Œç›®å½•ï¼š")
        for item in working_dir.iterdir():
            if item.is_file():
                size = item.stat().st_size
                print(f"ğŸ“„ {item.name} ({size} å­—èŠ‚)")
            else:
                file_count = len(list(item.iterdir()))
                print(f"ğŸ“ {item.name}/ ({file_count} ä¸ªæ–‡ä»¶)")
        
        print("\nğŸ’¡ åŠ¨æ‰‹å®éªŒï¼š")
        print("1. ç”¨æ–‡æœ¬ç¼–è¾‘å™¨æ‰“å¼€ .json æ–‡ä»¶ï¼Œè§‚å¯Ÿæ•°æ®æ ¼å¼")
        print("2. æ¢ç´¢å‘é‡å­˜å‚¨ç›®å½•ä¸­çš„æ–‡ä»¶")
        print("3. ç”¨å›¾å½¢å·¥å…·æ‰“å¼€ .graphml æ–‡ä»¶ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰")
        
    async def cleanup_demo(self):
        """æ¸…ç†æ¼”ç¤ºæ–‡ä»¶"""
        import shutil
        response = input("\nğŸ—‘ï¸ æ˜¯å¦åˆ é™¤æ¼”ç¤ºæ–‡ä»¶ï¼Ÿ(y/n): ")
        if response.lower() == 'y':
            shutil.rmtree(self.working_dir, ignore_errors=True)
            print("âœ… æ¼”ç¤ºæ–‡ä»¶å·²æ¸…ç†")

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“š Module 1: å­˜å‚¨ç³»ç»Ÿå­¦ä¹ ")
    print("å­¦ä¹ GraphRAGçš„æ•°æ®æŒä¹…åŒ–æœºåˆ¶")
    print("=" * 50)
    
    explorer = StorageExplorer()
    
    try:
        await explorer.demo_kv_storage()
        await explorer.demo_vector_storage()  
        await explorer.demo_graph_storage()
        explorer.explore_storage_files()
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥æ˜¯å¦å®‰è£…äº†æ‰€éœ€ä¾èµ–")
    finally:
        await explorer.cleanup_demo()
    
    print("\nğŸ¯ å­¦ä¹ å°ç»“ï¼š")
    print("1. KVå­˜å‚¨ï¼šç®€å•çš„é”®å€¼å¯¹ï¼Œé€‚åˆæ–‡æ¡£å’Œé…ç½®")
    print("2. å‘é‡å­˜å‚¨ï¼šæ”¯æŒç›¸ä¼¼æ€§æœç´¢ï¼Œé€‚åˆè¯­ä¹‰æ£€ç´¢")
    print("3. å›¾å­˜å‚¨ï¼šè¡¨ç¤ºå®ä½“å…³ç³»ï¼Œé€‚åˆçŸ¥è¯†å›¾è°±")
    print("\nâœ… Module 1 å®Œæˆï¼å‡†å¤‡å­¦ä¹  Module 2: æ–‡æœ¬å¤„ç†")

if __name__ == "__main__":
    asyncio.run(main()) 