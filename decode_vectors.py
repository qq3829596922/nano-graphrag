#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‘é‡æ•°æ®è§£ç è„šæœ¬
ç”¨äºè§£ç  nano-vectordb å­˜å‚¨çš„å‘é‡æ•°æ®
"""

import json
import base64
import numpy as np
import os


def decode_vector_database(json_file_path):
    """
    è§£ç å‘é‡æ•°æ®åº“æ–‡ä»¶
    
    Args:
        json_file_path (str): JSONæ–‡ä»¶è·¯å¾„
    """
    print(f"ğŸ” æ­£åœ¨è¯»å–æ–‡ä»¶: {json_file_path}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(json_file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {json_file_path}")
        return
    
    try:
        # è¯»å–JSONæ–‡ä»¶
        with open(json_file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print("âœ… JSONæ–‡ä»¶è¯»å–æˆåŠŸ!")
        
        # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
        print(f"\nğŸ“Š åŸºæœ¬ä¿¡æ¯:")
        print(f"   å‘é‡ç»´åº¦: {data.get('embedding_dim', 'Unknown')}")
        print(f"   å®ä½“æ•°é‡: {len(data.get('data', []))}")
        
        # æ˜¾ç¤ºå®ä½“åˆ—è¡¨
        print(f"\nğŸ‘¥ å®ä½“åˆ—è¡¨:")
        entities = data.get('data', [])
        for i, entity in enumerate(entities):
            entity_id = entity.get('__id__', 'Unknown')
            entity_name = entity.get('entity_name', 'Unknown')
            print(f"   {i+1:2d}. {entity_name} (ID: {entity_id[:20]}...)")
        
        # è§£ç å‘é‡çŸ©é˜µ
        matrix_encoded = data.get('matrix', '')
        if not matrix_encoded:
            print("âŒ æœªæ‰¾åˆ°å‘é‡æ•°æ®")
            return
        
        print(f"\nğŸ”“ æ­£åœ¨è§£ç å‘é‡æ•°æ®...")
        print(f"   ç¼–ç æ•°æ®é•¿åº¦: {len(matrix_encoded)} å­—ç¬¦")
        
        # Base64è§£ç 
        matrix_bytes = base64.b64decode(matrix_encoded)
        print(f"   äºŒè¿›åˆ¶æ•°æ®é•¿åº¦: {len(matrix_bytes)} å­—èŠ‚")
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        # nano-vectordb ä½¿ç”¨ float32 æ ¼å¼å­˜å‚¨
        matrix_array = np.frombuffer(matrix_bytes, dtype=np.float32)
        
        # é‡å¡‘ä¸ºçŸ©é˜µå½¢çŠ¶
        embedding_dim = data.get('embedding_dim', 1536)
        num_entities = len(entities)
        
        if len(matrix_array) != num_entities * embedding_dim:
            print(f"âš ï¸  æ•°æ®é•¿åº¦ä¸åŒ¹é…:")
            print(f"   æœŸæœ›: {num_entities} Ã— {embedding_dim} = {num_entities * embedding_dim}")
            print(f"   å®é™…: {len(matrix_array)}")
        
        # é‡å¡‘çŸ©é˜µ
        vectors = matrix_array.reshape(num_entities, embedding_dim)
        
        print(f"âœ… å‘é‡è§£ç æˆåŠŸ!")
        print(f"   çŸ©é˜µå½¢çŠ¶: {vectors.shape}")
        print(f"   æ•°æ®ç±»å‹: {vectors.dtype}")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“ˆ å‘é‡ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æœ€å°å€¼: {vectors.min():.6f}")
        print(f"   æœ€å¤§å€¼: {vectors.max():.6f}")
        print(f"   å¹³å‡å€¼: {vectors.mean():.6f}")
        print(f"   æ ‡å‡†å·®: {vectors.std():.6f}")
        
        # æ˜¾ç¤ºæ¯ä¸ªå®ä½“çš„å‘é‡ä¿¡æ¯
        print(f"\nğŸ”¢ å®ä½“å‘é‡è¯¦æƒ…:")
        for i, entity in enumerate(entities):
            entity_name = entity.get('entity_name', 'Unknown')
            vector = vectors[i]
            vector_norm = np.linalg.norm(vector)
            
            print(f"   {i+1:2d}. {entity_name}")
            print(f"       å‘é‡èŒƒæ•°: {vector_norm:.6f}")
            print(f"       å‰10ç»´åº¦: [{', '.join(f'{x:.4f}' for x in vector[:10])}...]")
            print(f"       å10ç»´åº¦: [...{', '.join(f'{x:.4f}' for x in vector[-10:])}]")
            
            # è¯¢é—®æ˜¯å¦æ˜¾ç¤ºå®Œæ•´å‘é‡
            if i == 0:  # åªå¯¹ç¬¬ä¸€ä¸ªå®ä½“è¯¢é—®
                show_full = input(f"\næ˜¯å¦æ˜¾ç¤ºå®Œæ•´çš„1536ç»´å‘é‡æ•°æ®ï¼Ÿ(y/n): ").strip().lower()
                if show_full == 'y':
                    print(f"       å®Œæ•´å‘é‡: {vector.tolist()}")
            print()
        
        # è®¡ç®—ç›¸ä¼¼åº¦ç¤ºä¾‹
        print("ğŸ” ç›¸ä¼¼åº¦è®¡ç®—ç¤ºä¾‹ (ä½™å¼¦ç›¸ä¼¼åº¦):")
        if len(vectors) >= 2:
            # è®¡ç®—å‰ä¸¤ä¸ªå®ä½“çš„ç›¸ä¼¼åº¦
            v1, v2 = vectors[0], vectors[1]
            similarity = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
            
            name1 = entities[0].get('entity_name', 'Entity 1')
            name2 = entities[1].get('entity_name', 'Entity 2')
            
            print(f"   {name1} vs {name2}")
            print(f"   ç›¸ä¼¼åº¦: {similarity:.6f}")
        
        # ä¿å­˜è§£ç ç»“æœ
        save_decoded_data(vectors, entities, json_file_path)
        
        return vectors, entities
        
    except Exception as e:
        print(f"âŒ è§£ç å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


def save_decoded_data(vectors, entities, original_file_path):
    """
    ä¿å­˜è§£ç åçš„æ•°æ®ä¸ºå¯è¯»æ ¼å¼
    
    Args:
        vectors (np.ndarray): è§£ç åçš„å‘é‡çŸ©é˜µ
        entities (list): å®ä½“åˆ—è¡¨
        original_file_path (str): åŸå§‹æ–‡ä»¶è·¯å¾„
    """
    base_name = os.path.splitext(original_file_path)[0]
    
    # ä¿å­˜ä¸ºå¯è¯»çš„JSONæ ¼å¼
    readable_data = {
        "metadata": {
            "total_entities": len(entities),
            "vector_dimension": vectors.shape[1],
            "data_type": str(vectors.dtype)
        },
        "entities_with_vectors": []
    }
    
    # æ·»åŠ æ¯ä¸ªå®ä½“çš„å‘é‡æ•°æ®
    for i, entity in enumerate(entities):
        entity_data = {
            "entity_name": entity.get('entity_name', ''),
            "entity_id": entity.get('__id__', ''),
            "vector": vectors[i].tolist(),  # è½¬æ¢ä¸ºPythonåˆ—è¡¨
            "vector_norm": float(np.linalg.norm(vectors[i]))
        }
        readable_data["entities_with_vectors"].append(entity_data)
    
    # ä¿å­˜ä¸ºæ ¼å¼åŒ–çš„JSONæ–‡ä»¶
    json_file = f"{base_name}_decoded.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(readable_data, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ å¯è¯»å‘é‡æ•°æ®å·²ä¿å­˜åˆ°: {json_file}")
    
    # ä¿å­˜ä¸ºç®€åŒ–çš„æ–‡æœ¬æ ¼å¼
    txt_file = f"{base_name}_vectors.txt"
    with open(txt_file, 'w', encoding='utf-8') as f:
        f.write("å‘é‡æ•°æ®è§£ç ç»“æœ\n")
        f.write("=" * 50 + "\n")
        f.write(f"å®ä½“æ•°é‡: {len(entities)}\n")
        f.write(f"å‘é‡ç»´åº¦: {vectors.shape[1]}\n")
        f.write("=" * 50 + "\n\n")
        
        for i, entity in enumerate(entities):
            entity_name = entity.get('entity_name', 'Unknown')
            vector = vectors[i]
            
            f.write(f"å®ä½“ {i+1}: {entity_name}\n")
            f.write(f"ID: {entity.get('__id__', '')}\n")
            f.write(f"å‘é‡èŒƒæ•°: {np.linalg.norm(vector):.6f}\n")
            f.write(f"å‘é‡æ•°æ®: {vector.tolist()}\n")
            f.write("-" * 30 + "\n\n")
    
    print(f"ğŸ’¾ æ–‡æœ¬æ ¼å¼æ•°æ®å·²ä¿å­˜åˆ°: {txt_file}")


def analyze_similarity(vectors, entities, top_k=5):
    """
    åˆ†æå®ä½“é—´çš„ç›¸ä¼¼åº¦
    
    Args:
        vectors (np.ndarray): å‘é‡çŸ©é˜µ
        entities (list): å®ä½“åˆ—è¡¨
        top_k (int): æ˜¾ç¤ºæœ€ç›¸ä¼¼çš„top_kä¸ªå®ä½“å¯¹
    """
    print(f"\nğŸ”— å®ä½“ç›¸ä¼¼åº¦åˆ†æ (Top {top_k}):")
    
    # è®¡ç®—æ‰€æœ‰å®ä½“å¯¹çš„ç›¸ä¼¼åº¦
    similarities = []
    
    for i in range(len(vectors)):
        for j in range(i + 1, len(vectors)):
            v1, v2 = vectors[i], vectors[j]
            similarity = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
            
            name1 = entities[i].get('entity_name', f'Entity {i}')
            name2 = entities[j].get('entity_name', f'Entity {j}')
            
            similarities.append((similarity, name1, name2))
    
    # æŒ‰ç›¸ä¼¼åº¦æ’åº
    similarities.sort(key=lambda x: x[0], reverse=True)
    
    # æ˜¾ç¤ºæœ€ç›¸ä¼¼çš„å®ä½“å¯¹
    for i, (sim, name1, name2) in enumerate(similarities[:top_k]):
        print(f"   {i+1:2d}. {name1} â†” {name2}")
        print(f"       ç›¸ä¼¼åº¦: {sim:.6f}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å‘é‡æ•°æ®è§£ç å·¥å…·")
    print("=" * 50)
    
    # é»˜è®¤æ–‡ä»¶è·¯å¾„
    default_file = "mytest/vdb_entities.json"
    
    # æ£€æŸ¥é»˜è®¤æ–‡ä»¶
    if os.path.exists(default_file):
        print(f"ğŸ“ æ‰¾åˆ°é»˜è®¤æ–‡ä»¶: {default_file}")
        file_path = default_file
    else:
        # è®©ç”¨æˆ·è¾“å…¥æ–‡ä»¶è·¯å¾„
        file_path = input("è¯·è¾“å…¥ vdb_entities.json æ–‡ä»¶è·¯å¾„: ").strip()
        if not file_path:
            print("âŒ æœªæä¾›æ–‡ä»¶è·¯å¾„")
            return
    
    # è§£ç å‘é‡æ•°æ®
    result = decode_vector_database(file_path)
    
    if result:
        vectors, entities = result
        
        # è¿›è¡Œç›¸ä¼¼åº¦åˆ†æ
        analyze_similarity(vectors, entities)
        
        print(f"\nğŸ‰ è§£ç å®Œæˆï¼")
        print(f"   å…±è§£ç  {len(entities)} ä¸ªå®ä½“çš„ {vectors.shape[1]} ç»´å‘é‡")


if __name__ == "__main__":
    main() 